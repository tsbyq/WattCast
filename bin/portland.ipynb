{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r\"..\") # should be the git repo root directory\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory: \" + cwd)\n",
    "assert os.getcwd()[-8:] == \"WattCast\", \"Current working directory is not the git repo root directory\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file_path.csv' with the actual path to your CSV file\n",
    "df = pd.read_csv(os.path.join(cwd, 'data', 'raw_data', 'Portland_load_profile.csv'))\n",
    "\n",
    "start_date = '2021-01-01 00:00:00'\n",
    "end_date = pd.to_datetime(start_date) + pd.DateOffset(hours=8759)\n",
    "datetime_series = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "df['datetime'] = datetime_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your CSV file has two columns: 'timestamp' and 'value'\n",
    "# Adjust the column names accordingly to match your dataset\n",
    "time_series = TimeSeries.from_dataframe(df, 'datetime', 'Electric_MW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"==>> time_series.width: {time_series.width}\")\n",
    "time_series = time_series.add_datetime_attribute(attribute='weekday', cyclic=True).add_datetime_attribute(attribute='day', cyclic=True).add_datetime_attribute(attribute='month', cyclic=True)\n",
    "print(f\"==>> time_series.width: {time_series.width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a size of 15x5\n",
    "plt.figure(figsize=(25, 5))\n",
    "\n",
    "# Plot the TimeSeries\n",
    "time_series.plot()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a size of 15x5\n",
    "plt.figure(figsize=(25, 5))\n",
    "\n",
    "# Plot the TimeSeries\n",
    "time_series[['day_sin', 'day_cos']].plot()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series.add_holidays(country_code='US', prov='CA')['holidays']\n",
    "\n",
    "print(f\"==>> time_series.start_time(): {time_series.start_time()}\")\n",
    "print(f\"==>> time_series.end_time(): {time_series.end_time()}\")\n",
    "\n",
    "time_series.gaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a custom pytorch dataset class for time series data\n",
    "# The following are high-level principles:\n",
    "# 1. The dataset class should inherit from torch.utils.data.Dataset\n",
    "# 2. The class \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df[['datetime', 'Electric_MW']].copy(deep=True)\n",
    "\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, history_length=5, forecast_length=2):\n",
    "        self.data = data\n",
    "        self.history_length = history_length\n",
    "        self.forecast_length = forecast_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the historical data and target values for the current index\n",
    "        history = self.data[index:index+self.history_length].values()\n",
    "        target = self.data[index+self.history_length:index+self.history_length+self.forecast_length].values()\n",
    "\n",
    "        return history, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.history_length - self.forecast_length + 1\n",
    "\n",
    "\n",
    "df_t = pd.read_csv('E:/GitHub/Forked_Repos/WattCast/df_tt.csv')\n",
    "# Assuming your DataFrame is named 'df' with columns 'datetime' and 'value'\n",
    "series = TimeSeries.from_dataframe(df_t, 'datetime', 'Electric_MW')\n",
    "\n",
    "# Define the seasonal chunks\n",
    "num_chunks = 4\n",
    "chunk_length = len(series) // num_chunks\n",
    "\n",
    "# Define the split percentages for each chunk\n",
    "split_pcts = [0.7, 0.2, 0.1]\n",
    "\n",
    "# Initialize lists to store the split datasets\n",
    "train_chunks = []\n",
    "val_chunks = []\n",
    "test_chunks = []\n",
    "\n",
    "# Split the dataset into chunks and apply split percentages\n",
    "for i in range(num_chunks):\n",
    "    start_index = i * chunk_length\n",
    "    end_index = (i + 1) * chunk_length\n",
    "\n",
    "    chunk = series[start_index:end_index]\n",
    "\n",
    "    split_sizes = np.array(split_pcts) * len(chunk)\n",
    "    train_chunk = chunk[:int(split_sizes[0])]\n",
    "    val_chunk = chunk[int(split_sizes[0]):int(split_sizes[0] + split_sizes[1])]\n",
    "    test_chunk = chunk[int(split_sizes[0] + split_sizes[1]):]\n",
    "\n",
    "    train_chunks.append(train_chunk)\n",
    "    val_chunks.append(val_chunk)\n",
    "    test_chunks.append(test_chunk)\n",
    "\n",
    "# Concatenate the chunks back together\n",
    "train_series = train_chunks[0]\n",
    "val_series = val_chunks[0]\n",
    "test_series = test_chunks[0]\n",
    "\n",
    "# for i in range(1, num_chunks):\n",
    "#     train_series += train_chunks[i]\n",
    "#     val_series += val_chunks[i]\n",
    "#     test_series += test_chunks[i]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_series)\n",
    "val_dataset = TimeSeriesDataset(val_series)\n",
    "test_dataset = TimeSeriesDataset(test_series)\n",
    "\n",
    "# batch_size = 32\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 5))\n",
    "train_chunks[0].plot(color='blue', label='train-chunk-1')\n",
    "train_chunks[1].plot(color='blue', label='train-chunk-2')\n",
    "train_chunks[2].plot(color='blue', label='train-chunk-3')\n",
    "train_chunks[3].plot(color='blue', label='train-chunk-4')\n",
    "val_chunks[0].plot(color='orange', label='val-chunk-1')\n",
    "val_chunks[1].plot(color='orange', label='val-chunk-2')\n",
    "val_chunks[2].plot(color='orange', label='val-chunk-3')\n",
    "val_chunks[3].plot(color='orange', label='val-chunk-4')\n",
    "test_chunks[0].plot(color='green', label='test-chunk-1')\n",
    "test_chunks[1].plot(color='green', label='test-chunk-2')\n",
    "test_chunks[2].plot(color='green', label='test-chunk-3')\n",
    "test_chunks[3].plot(color='green', label='test-chunk-4')\n",
    "# Move legend to the right, outside of plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# Show plot axes lines\n",
    "plt.axhline(0, color='black', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data_list, history_length=5, forecast_length=2):\n",
    "        self.data_list = data_list\n",
    "        self.history_length = history_length\n",
    "        self.forecast_length = forecast_length\n",
    "        self.lengths = [len(data) - history_length - forecast_length + 1 for data in self.data_list]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Find the corresponding time series chunk and index within the chunk\n",
    "        cum_lengths = np.cumsum(self.lengths)\n",
    "        chunk_index = np.searchsorted(cum_lengths, index + 1)\n",
    "        if chunk_index == 0:\n",
    "            data_index = index\n",
    "        else:\n",
    "            data_index = int(index - cum_lengths[chunk_index - 1])\n",
    "\n",
    "        print(f\"==>> item_index: {index}, chunk_index: {chunk_index}, data_index: {data_index}\")\n",
    "        # Get the historical data and target values for the current index\n",
    "        history = self.data_list[chunk_index][data_index:data_index+self.history_length].values().copy()\n",
    "        target = self.data_list[chunk_index][data_index+self.history_length:data_index+self.history_length+self.forecast_length].values().copy()\n",
    "\n",
    "        return history, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('E:/GitHub/Forked_Repos/WattCast/df_tt.csv', parse_dates=['datetime'])\n",
    "\n",
    "# Assuming your DataFrame is named 'df' with columns 'datetime' and 'value'\n",
    "series = TimeSeries.from_dataframe(df, 'datetime', 'Electric_MW')\n",
    "\n",
    "# Define the seasonal chunks\n",
    "num_chunks = 4\n",
    "chunk_length = len(series) // num_chunks\n",
    "\n",
    "# Define the split percentages for each chunk\n",
    "split_pcts = [0.7, 0.2, 0.1]\n",
    "\n",
    "# Initialize lists to store the split datasets\n",
    "train_chunks = []\n",
    "val_chunks = []\n",
    "test_chunks = []\n",
    "\n",
    "# Split the dataset into chunks and apply split percentages\n",
    "for i in range(num_chunks):\n",
    "    start_index = i * chunk_length\n",
    "    end_index = (i + 1) * chunk_length\n",
    "\n",
    "    chunk = series[start_index:end_index]\n",
    "\n",
    "    split_sizes = np.array(split_pcts) * len(chunk)\n",
    "    train_chunk = chunk[:int(split_sizes[0])]\n",
    "    val_chunk = chunk[int(split_sizes[0]):int(split_sizes[0] + split_sizes[1])]\n",
    "    test_chunk = chunk[int(split_sizes[0] + split_sizes[1]):]\n",
    "\n",
    "    train_chunks.append(train_chunk)\n",
    "    val_chunks.append(val_chunk)\n",
    "    test_chunks.append(test_chunk)\n",
    "\n",
    "# Concatenate the chunks back together\n",
    "train_dataset = TimeSeriesDataset(train_chunks)\n",
    "val_dataset = TimeSeriesDataset(val_chunks)\n",
    "test_dataset = TimeSeriesDataset(test_chunks)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i, (inputs, targets) in enumerate(train_loader):\n",
    "    if i < 10: continue\n",
    "\n",
    "    # print(inputs.shape, targets.shape)\n",
    "    print(f\"==>> inputs: \\n{inputs}\")\n",
    "    print(f\"==>> targets: \\n{targets}\")\n",
    "    print('-'*80)\n",
    "    # if i == 1: break\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wattcast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
